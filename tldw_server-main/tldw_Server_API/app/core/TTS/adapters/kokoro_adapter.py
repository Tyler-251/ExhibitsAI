# kokoro_adapter.py
# Description: Kokoro TTS adapter implementation
#
# Imports
import os
import re
from typing import Optional, Dict, Any, AsyncGenerator, Set, List, Tuple
#
# Third-party Imports
import numpy as np
from loguru import logger
#
# Local Imports
from .base import (
    TTSAdapter,
    TTSCapabilities,
    TTSRequest,
    TTSResponse,
    AudioFormat,
    VoiceInfo,
    ProviderStatus
)
from ..tts_exceptions import (
    TTSProviderNotConfiguredError,
    TTSProviderInitializationError,
    TTSModelNotFoundError,
    TTSModelLoadError,
    TTSGenerationError,
    TTSResourceError,
    TTSInsufficientMemoryError
)
from ..tts_validation import validate_tts_request
from ..tts_resource_manager import get_resource_manager
#
#######################################################################################################################
#
# Kokoro TTS Adapter Implementation

class KokoroAdapter(TTSAdapter):
    """Adapter for Kokoro TTS (ONNX and PyTorch variants)"""

    # Kokoro voice definitions
    VOICES = {
        "af_bella": VoiceInfo(
            id="af_bella",
            name="Bella",
            gender="female",
            language="en-us",
            description="American female voice"
        ),
        "af_sky": VoiceInfo(
            id="af_sky",
            name="Sky",
            gender="female",
            language="en-us",
            description="Young American female voice"
        ),
        "af_heart": VoiceInfo(
            id="af_heart",
            name="Heart",
            gender="female",
            language="en-us",
            description="Warm American female voice"
        ),
        "am_adam": VoiceInfo(
            id="am_adam",
            name="Adam",
            gender="male",
            language="en-us",
            description="American male voice"
        ),
        "am_michael": VoiceInfo(
            id="am_michael",
            name="Michael",
            gender="male",
            language="en-us",
            description="Deep American male voice"
        ),
        "bf_emma": VoiceInfo(
            id="bf_emma",
            name="Emma",
            gender="female",
            language="en-gb",
            description="British female voice"
        ),
        "bf_isabella": VoiceInfo(
            id="bf_isabella",
            name="Isabella",
            gender="female",
            language="en-gb",
            description="Elegant British female voice"
        ),
        "bm_george": VoiceInfo(
            id="bm_george",
            name="George",
            gender="male",
            language="en-gb",
            description="British male voice"
        ),
        "bm_lewis": VoiceInfo(
            id="bm_lewis",
            name="Lewis",
            gender="male",
            language="en-gb",
            description="Young British male voice"
        )
    }

    # Chunking configuration (from Kokoro-FastAPI)
    CHUNK_CONFIG = {
        "target_min_tokens": 30,  # Lowered for testing
        "target_max_tokens": 60,  # Lowered for testing (80 tokens in test > 60)
        "absolute_max_tokens": 150  # Lowered for testing
    }

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        super().__init__(config)

        # Determine backend type (ONNX or PyTorch)
        self.use_onnx = self.config.get("kokoro_use_onnx", True)
        # Device selection with fallback
        preferred = self.config.get("kokoro_device")
        try:
            import torch  # type: ignore
            cuda_avail = torch.cuda.is_available()
            mps_avail = hasattr(torch.backends, 'mps') and getattr(torch.backends.mps, 'is_available', lambda: False)()
        except Exception:
            cuda_avail = False
            mps_avail = False
        if preferred:
            pref = str(preferred).lower()
            if pref == "cuda":
                self.device = "cuda" if cuda_avail else "cpu"
            elif pref == "mps":
                self.device = "mps" if mps_avail else ("cuda" if cuda_avail else "cpu")
            elif pref == "cpu":
                self.device = "cpu"
            else:
                self.device = "cuda" if cuda_avail else "cpu"
        else:
            self.device = "cuda" if cuda_avail else "cpu"

        # Model paths
        self.model_path = self.config.get("kokoro_model_path", "kokoro-v0_19.onnx")
        # Maintain both attribute names for compatibility with tests and internal code
        self.voices_json_path = self.config.get("kokoro_voices_json", "voices.json")
        self.voices_json = self.voices_json_path
        self.voice_dir = self.config.get("kokoro_voice_dir", "voices")

        # Auto-download toggle (Kokoro does not auto-download; provided for consistency)
        def _parse_bool(val, default=True):
            if isinstance(val, bool):
                return val
            if val is None:
                return default
            s = str(val).strip().lower()
            if s in ("1", "true", "yes", "on"): return True
            if s in ("0", "false", "no", "off"): return False
            return default
        cfg_auto = self.config.get("kokoro_auto_download")
        env_auto = os.getenv("KOKORO_AUTO_DOWNLOAD") or os.getenv("TTS_AUTO_DOWNLOAD")
        self.auto_download = _parse_bool(cfg_auto, _parse_bool(env_auto, True))

        # Text processing settings
        self.normalize_text = self.config.get("normalize_text", True)
        self.sentence_splitting = self.config.get("sentence_splitting", True)

        # Performance settings
        self.sample_rate = self.config.get("sample_rate", 24000)

        # Model instances
        self.kokoro_instance = None
        self.model_pt = None
        self.kokoro_pt_model = None  # KModel when using PyTorch backend
        self.kokoro_pt_pipelines = {}
        self.tokenizer = None
        self.audio_normalizer = None
        self._dynamic_voices: List[VoiceInfo] = []

    async def initialize(self) -> bool:
        """Initialize the Kokoro adapter"""
        try:
            # Import audio normalizer
            from tldw_Server_API.app.core.TTS.streaming_audio_writer import AudioNormalizer
            self.audio_normalizer = AudioNormalizer()

            if self.use_onnx:
                success = await self._load_onnx_model()
            else:
                success = await self._load_pytorch_model()

            # Load dynamic voices if available
            try:
                self._load_dynamic_voices()
            except Exception as ve:
                logger.warning(f"{self.provider_name}: Failed to load dynamic voices.json: {ve}")

            if success:
                logger.info(f"{self.provider_name}: Initialized successfully (Backend: {'ONNX' if self.use_onnx else 'PyTorch'}, Device: {self.device})")
                self._status = ProviderStatus.AVAILABLE
                return True
            else:
                self._status = ProviderStatus.ERROR
                return False

        except Exception as e:
            logger.error(f"{self.provider_name}: Initialization failed: {e}")
            self._status = ProviderStatus.ERROR
            return False

    async def _initialize_onnx(self) -> bool:
        """Initialize ONNX backend"""
        try:
            from kokoro_onnx import Kokoro, EspeakConfig

            # Check model files exist
            if not os.path.exists(self.model_path):
                raise TTSModelNotFoundError(
                    f"Kokoro ONNX model not found at {self.model_path}",
                    provider=self.provider_name,
                    details={"model_path": self.model_path}
                )

            if not os.path.exists(self.voices_json_path):
                raise TTSModelNotFoundError(
                    f"Kokoro voices.json not found at {self.voices_json_path}",
                    provider=self.provider_name,
                    details={"voices_json": self.voices_json_path}
                )

            # Configure eSpeak
            espeak_lib = os.getenv("PHONEMIZER_ESPEAK_LIBRARY")
            espeak_config = EspeakConfig(lib_path=espeak_lib) if espeak_lib else None

            # Initialize Kokoro
            self.kokoro_instance = Kokoro(
                self.model_path,
                self.voices_json_path,
                espeak_config=espeak_config
            )

            logger.info(f"{self.provider_name}: ONNX model loaded successfully")
            return True

        except ImportError as e:
            logger.error(f"{self.provider_name}: kokoro_onnx library not installed")
            raise TTSModelLoadError(
                "Failed to import kokoro_onnx library",
                provider=self.provider_name,
                details={"error": str(e), "suggestion": "pip install kokoro-onnx"}
            )
        except TTSModelNotFoundError:
            raise
        except Exception as e:
            logger.error(f"{self.provider_name}: ONNX initialization error: {e}")
            raise TTSModelLoadError(
                "Failed to initialize ONNX model",
                provider=self.provider_name,
                details={"error": str(e), "model_path": self.model_path}
            )

    async def _initialize_pytorch(self) -> bool:
        """Initialize PyTorch backend"""
        try:
            import torch
        except ImportError as e:
            raise TTSModelLoadError(
                "PyTorch is required for Kokoro PyTorch backend",
                provider=self.provider_name,
                details={"error": str(e), "suggestion": "pip install torch"}
            )
        # Check model file
        if not os.path.exists(self.model_path):
            raise TTSModelNotFoundError(
                f"Kokoro PyTorch model not found at {self.model_path}",
                provider=self.provider_name,
                details={"model_path": self.model_path}
            )
        # Try native Kokoro PyTorch if available
        try:
            from kokoro import KModel  # type: ignore
            # config.json expected alongside model
            config_path = os.path.join(os.path.dirname(self.model_path), "config.json")
            if not os.path.exists(config_path):
                raise TTSModelLoadError(
                    "Kokoro config.json not found for PyTorch backend",
                    provider=self.provider_name,
                    details={"config_path": config_path}
                )
            self.kokoro_pt_model = KModel(config=config_path, model=self.model_path).eval()
            # Move to device
            dev = str(self.device).lower()
            if dev.startswith("cuda"):
                try:
                    self.kokoro_pt_model = self.kokoro_pt_model.cuda()
                except Exception:
                    pass
            elif dev == "mps":
                try:
                    self.kokoro_pt_model = self.kokoro_pt_model.to(torch.device("mps"))
                except Exception:
                    logger.warning("MPS device not available; using CPU for Kokoro")
                    self.kokoro_pt_model = self.kokoro_pt_model.cpu()
            else:
                self.kokoro_pt_model = self.kokoro_pt_model.cpu()
            logger.info(f"{self.provider_name}: Kokoro PyTorch model loaded on {dev}")
            return True
        except ImportError:
            # Fallback: generic torch.load
            try:
                try:
                    self.model_pt = torch.jit.load(self.model_path, map_location=self.device)
                except Exception:
                    self.model_pt = torch.load(self.model_path, map_location=self.device)
                try:
                    self.model_pt.eval()
                except Exception:
                    pass
                logger.info(f"{self.provider_name}: Loaded generic PyTorch model on {self.device}")
                return True
            except Exception as e:
                raise TTSModelLoadError(
                    "Failed to initialize PyTorch model",
                    provider=self.provider_name,
                    details={"error": str(e), "model_path": self.model_path}
                )

    # Thin wrapper methods for tests to patch
    async def _load_onnx_model(self) -> bool:
        return await self._initialize_onnx()

    async def _load_pytorch_model(self) -> bool:
        return await self._initialize_pytorch()

    async def get_capabilities(self) -> TTSCapabilities:
        """Get Kokoro TTS capabilities"""
        all_voices = list(self.VOICES.values()) + self._dynamic_voices
        return TTSCapabilities(
            provider_name="Kokoro",
            supported_languages={"en-us", "en-gb", "en"},
            supported_voices=all_voices,
            supported_formats={
                AudioFormat.MP3,
                AudioFormat.WAV,
                AudioFormat.OPUS,
                AudioFormat.FLAC,
                AudioFormat.PCM
            },
            max_text_length=500,
            supports_streaming=True,
            supports_voice_cloning=False,
            supports_emotion_control=False,
            supports_speech_rate=True,
            supports_pitch_control=False,
            supports_volume_control=False,
            supports_ssml=False,
            supports_phonemes=True,  # Kokoro uses phoneme-based generation
            supports_multi_speaker=True,  # Through voice mixing
            supports_background_audio=False,
            latency_ms=300 if self.device == "cuda" else 3500,  # From Kokoro-FastAPI
            sample_rate=self.sample_rate,
            default_format=AudioFormat.WAV
        )

    async def generate(self, request: TTSRequest) -> TTSResponse:
        """Generate speech using Kokoro TTS"""
        if not await self.ensure_initialized():
            raise TTSProviderNotConfiguredError(
                f"{self.provider_name} not initialized",
                provider=self.provider_name
            )

        # Validate request using new validation system
        try:
            validate_tts_request(request, provider=self.provider_name.lower())
        except Exception as e:
            logger.error(f"{self.provider_name} request validation failed: {e}")
            raise

        # Process voice (support for voice mixing like "af_bella(2)+af_sky(1)")
        voice = self._process_voice(request.voice or "af_bella")

        # Preprocess text
        text = self.preprocess_text(request.text)

        # Determine language from voice
        lang = self._get_language_from_voice(voice)

        logger.info(
            f"{self.provider_name}: Generating speech with voice={voice}, "
            f"lang={lang}, format={request.format.value}"
        )

        try:
            if request.stream:
                # Return streaming response
                return TTSResponse(
                    audio_stream=self._stream_audio_kokoro(text, voice, lang, request),
                    format=request.format,
                    sample_rate=self.sample_rate,
                    channels=1,
                    voice_used=voice,
                    provider=self.provider_name
                )
            else:
                # Generate complete audio
                audio_data = await self._generate_complete_kokoro(text, voice, lang, request)
                return TTSResponse(
                    audio_data=audio_data,
                    format=request.format,
                    sample_rate=self.sample_rate,
                    channels=1,
                    voice_used=voice,
                    provider=self.provider_name
                )

        except Exception as e:
            logger.error(f"{self.provider_name} generation error: {e}")
            raise

    async def _stream_audio_kokoro(
        self,
        text: str,
        voice: str,
        lang: str,
        request: TTSRequest
    ) -> AsyncGenerator[bytes, None]:
        """Stream audio from Kokoro"""
        if self.use_onnx:
            if not self.kokoro_instance:
                raise ValueError("Kokoro ONNX not initialized")
        else:
            if self.kokoro_pt_model is None and self.model_pt is None:
                raise ValueError("Kokoro PyTorch model not initialized")

        # Import StreamingAudioWriter for format conversion
        from tldw_Server_API.app.core.TTS.streaming_audio_writer import StreamingAudioWriter

        # Create audio writer for target format
        writer = StreamingAudioWriter(
            format=request.format.value,
            sample_rate=self.sample_rate,
            channels=1
        )

        try:
            chunk_count = 0
            # Stream audio chunks
            if self.use_onnx:
                stream_iter = self.kokoro_instance.create_stream(
                    text,
                    voice=voice,
                    speed=request.speed,
                    lang=lang
                )
            else:
                # Use Kokoro PyTorch pipeline if available
                try:
                    from kokoro import KPipeline  # type: ignore
                except ImportError:
                    # Cannot proceed without kokoro pipeline
                    raise TTSGenerationError(
                        "Kokoro PyTorch generation requires 'kokoro' package",
                        provider=self.provider_name,
                        details={"suggestion": "pip install kokoro-tts or Kokoro PyTorch package"}
                    )
                # Determine voice path if a voice file exists
                voice_path = voice
                try:
                    # Attempt to resolve to a .pt file under configured voice_dir if voice looks like an id
                    if self.voice_dir and isinstance(voice, str) and os.path.isdir(self.voice_dir):
                        candidate = os.path.join(self.voice_dir, f"{voice}.pt")
                        if os.path.exists(candidate):
                            voice_path = candidate
                except Exception:
                    pass
                # Pick pipeline by language code (first letter fallback)
                lang_code = lang.split('-')[0][0] if '-' in lang else (lang[0] if lang else 'e')
                key = lang_code
                if key not in self.kokoro_pt_pipelines:
                    self.kokoro_pt_pipelines[key] = KPipeline(
                        lang_code=key,
                        model=self.kokoro_pt_model,
                        device=str(self.device)
                    )
                pipeline = self.kokoro_pt_pipelines[key]

                # Define a sync generator wrapper to async iterate
                def _sync_iter():
                    for result in pipeline(text, voice=voice_path, speed=request.speed, model=self.kokoro_pt_model):
                        yield result

                async def _async_iter():
                    for result in _sync_iter():
                        yield result

                stream_iter = _async_iter()

            async for samples_chunk, sr_chunk in stream_iter:
                if samples_chunk is not None and len(samples_chunk) > 0:
                    chunk_count += 1

                    # Normalize float32 samples to int16
                    normalized_chunk = self.audio_normalizer.normalize(
                        samples_chunk,
                        target_dtype=np.int16
                    )

                    # Write chunk and get encoded bytes
                    encoded_bytes = writer.write_chunk(normalized_chunk)
                    if encoded_bytes:
                        yield encoded_bytes
                        logger.debug(f"{self.provider_name}: Yielded chunk {chunk_count}, {len(encoded_bytes)} bytes")

            # Finalize stream
            final_bytes = writer.write_chunk(finalize=True)
            if final_bytes:
                yield final_bytes
                logger.debug(f"{self.provider_name}: Yielded final chunk, {len(final_bytes)} bytes")

            logger.info(f"{self.provider_name}: Successfully streamed {chunk_count} chunks")

        except Exception as e:
            logger.error(f"{self.provider_name} streaming error: {e}")
            raise
        finally:
            writer.close()

    async def _generate_complete_kokoro(
        self,
        text: str,
        voice: str,
        lang: str,
        request: TTSRequest
    ) -> bytes:
        """Generate complete audio from Kokoro"""
        # Collect all streamed chunks
        all_audio = b""
        async for chunk in self._stream_audio_kokoro(text, voice, lang, request):
            all_audio += chunk
        return all_audio

    def _process_voice(self, voice: str) -> str:
        """
        Process voice string, supporting voice mixing.
        Examples:
        - "af_bella" -> "af_bella"
        - "af_bella(2)+af_sky(1)" -> mixed voice
        """
        # Check if it's a mixed voice pattern
        if "+" in voice and "(" in voice:
            # This is a mixed voice, return as-is for Kokoro to handle
            return voice

        # Map generic voice names to Kokoro voices
        if voice not in self.VOICES:
            # Try to find a suitable voice
            voice = self.map_voice(voice)

        return voice

    def _load_dynamic_voices(self) -> None:
        """Load voices from voices.json and merge with static voices.

        Expected JSON structure (array of entries):
        [{"id": "af_bella", "name": "Bella", "gender": "female", "language": "en-us", "description": "..."}, ...]
        """
        path = self.voices_json
        if not path or not os.path.exists(path):
            return
        import json
        with open(path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        dyn: List[VoiceInfo] = []
        if isinstance(data, dict) and "voices" in data:
            entries = data["voices"]
        else:
            entries = data
        if not isinstance(entries, list):
            return
        # Existing ids to avoid duplicates
        existing_ids = set(self.VOICES.keys()) | {v.id for v in self._dynamic_voices}
        for entry in entries:
            try:
                vid = str(entry.get("id") or entry.get("voice_id") or "").strip()
                if not vid or vid in existing_ids:
                    continue
                vinfo = VoiceInfo(
                    id=vid,
                    name=str(entry.get("name") or vid),
                    gender=entry.get("gender"),
                    language=str(entry.get("language") or "en"),
                    description=entry.get("description")
                )
                dyn.append(vinfo)
                existing_ids.add(vid)
            except Exception:
                continue
        self._dynamic_voices = dyn

    def _get_language_from_voice(self, voice: str) -> str:
        """Get language code from voice ID"""
        # Handle mixed voices
        if "+" in voice:
            # Extract first voice from mix
            first_voice = voice.split("+")[0].split("(")[0].strip()
        else:
            first_voice = voice

        # Determine language from voice prefix
        if first_voice.startswith("a"):
            return "en-us"  # American
        elif first_voice.startswith("b"):
            return "en-gb"  # British
        else:
            return "en-us"  # Default to American

    def map_voice(self, voice_id: str) -> str:
        """Map generic voice ID to Kokoro voice"""
        # Check if it's already a valid Kokoro voice
        if voice_id in self.VOICES:
            return voice_id

        # Try common mappings
        voice_mappings = {
            "female": "af_bella",
            "male": "am_adam",
            "british_female": "bf_emma",
            "british_male": "bm_george",
            "american_female": "af_bella",
            "american_male": "am_adam",
            "young_female": "af_sky",
            "deep_male": "am_michael",
            "warm": "af_heart",
            "child": "af_nicole",
        }

        return voice_mappings.get(voice_id.lower(), "af_bella")

    def preprocess_text(self, text: str, **kwargs) -> str:
        """Preprocess text for Kokoro"""
        # Strip excess whitespace
        text = text.strip()

        # Normalize text if enabled
        if self.normalize_text:
            # Basic normalization (Kokoro handles most of this internally)
            text = re.sub(r'\s+', ' ', text)  # Normalize whitespace
            text = re.sub(r'["""]', '"', text)  # Normalize quotes
            text = re.sub(r'['']', "'", text)  # Normalize apostrophes

        return text

    def chunk_text(self, text: str) -> List[str]:
        """
        Chunk text for optimal Kokoro processing.
        Based on Kokoro-FastAPI chunking strategy.
        """
        # Simple sentence-based chunking
        import re

        # Split on sentence boundaries
        sentences = re.split(r'(?<=[.!?])\s+', text)

        chunks = []
        current_chunk = ""

        for sentence in sentences:
            # Estimate token count (rough approximation: 1 token â‰ˆ 4 chars)
            current_plus_sentence = current_chunk + (" " + sentence if current_chunk else sentence)
            estimated_tokens = len(current_plus_sentence) / 4

            if estimated_tokens < self.CHUNK_CONFIG["target_max_tokens"]:
                current_chunk = current_plus_sentence
            else:
                if current_chunk:
                    chunks.append(current_chunk.strip())
                current_chunk = sentence

        if current_chunk:
            chunks.append(current_chunk.strip())

        return chunks

    async def _cleanup_resources(self):
        """Clean up Kokoro adapter resources"""
        try:
            # Clean up ONNX instance
            if self.kokoro_instance:
                self.kokoro_instance = None
                logger.debug(f"{self.provider_name}: ONNX instance cleared")

            # Clean up PyTorch model and tokenizer
            if self.model_pt:
                self.model_pt = None
                logger.debug(f"{self.provider_name}: PyTorch model cleared")

            if self.tokenizer:
                self.tokenizer = None
                logger.debug(f"{self.provider_name}: Tokenizer cleared")

            # Clear normalizer
            if self.audio_normalizer:
                self.audio_normalizer = None
            # Clear optionally present attributes used in tests
            if hasattr(self, 'model'):
                self.model = None
            if hasattr(self, 'phonemizer'):
                self.phonemizer = None

            # Clear CUDA cache if using GPU
            if self.device.startswith("cuda"):
                try:
                    import torch
                    if torch.cuda.is_available():
                        torch.cuda.empty_cache()
                        logger.debug(f"{self.provider_name}: CUDA cache cleared")
                except ImportError:
                    pass

        except Exception as e:
            logger.warning(f"{self.provider_name}: Error during cleanup: {e}")

#
# End of kokoro_adapter.py
#######################################################################################################################
