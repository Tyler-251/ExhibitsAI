# ================================================
# tldw_server Complete Configuration Template
# ================================================
# This file contains ALL sensitive configuration (API keys, secrets, passwords)
# Copy this file to .env and add your actual values
# SECURITY WARNING: Never commit the actual .env file to version control!
# ================================================

# ================================================
# AUTHENTICATION & SECURITY
# ================================================

# --- Application Mode ---
# Options: single_user, multi_user
AUTH_MODE=single_user

# --- Single-User Mode ---
# API key for single-user mode (auto-generated if not set)
# Generate with: python -c "import secrets; print(secrets.token_urlsafe(32))"
SINGLE_USER_API_KEY=CHANGE_ME_TO_SECURE_API_KEY

# --- Multi-User Mode (JWT) ---
# REQUIRED for multi-user mode: Generate a secure random key (minimum 32 characters)
# Generate with: python -c "import secrets; print(secrets.token_urlsafe(32))"
JWT_SECRET_KEY=CHANGE_ME_TO_SECURE_RANDOM_KEY_MIN_32_CHARS

# Token expiration times
ACCESS_TOKEN_EXPIRE_MINUTES=30
REFRESH_TOKEN_EXPIRE_DAYS=7
JWT_ALGORITHM=HS256

# --- Encryption Keys ---
# Session token encryption key (auto-generated from JWT secret if not set)
# Generate with: python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
SESSION_ENCRYPTION_KEY=

# API key pepper for additional hashing security (optional but recommended)
# Generate with: python -c "import secrets; print(secrets.token_hex(32))"
API_KEY_PEPPER=

# ================================================
# DATABASE CONFIGURATION
# ================================================

# For PostgreSQL (recommended for multi-user production):
# DATABASE_URL=postgresql://username:password@localhost:5432/tldw_db

# For SQLite (development or single-user):
DATABASE_URL=sqlite:///./Databases/users.db

# Database connection pool settings (PostgreSQL only)
DATABASE_POOL_MIN_SIZE=5
DATABASE_POOL_MAX_SIZE=20
DATABASE_MAX_QUERIES=50000
DATABASE_MAX_INACTIVE_CONNECTION_LIFETIME=300

# ================================================
# REDIS CONFIGURATION (Optional)
# ================================================
# Redis for session caching and rate limiting (improves performance)
# REDIS_URL=redis://localhost:6379/0
# REDIS_HOST=localhost
# REDIS_PORT=6379
# REDIS_DB=0
# REDIS_MAX_CONNECTIONS=50
# REDIS_ENABLED=false
# CACHE_TTL=300

# ================================================
# LLM PROVIDER API KEYS
# ================================================

# --- OpenAI ---
# For GPT models and embeddings
OPENAI_API_KEY=

# --- Anthropic ---
# For Claude models
ANTHROPIC_API_KEY=

# --- Cohere ---
# For Command models
COHERE_API_KEY=

# --- Google ---
# For Gemini models
GOOGLE_API_KEY=

# --- Groq ---
# For fast inference with open models
GROQ_API_KEY=

# --- DeepSeek ---
# For DeepSeek models
DEEPSEEK_API_KEY=

# --- Mistral ---
# For Mistral models
MISTRAL_API_KEY=

# --- HuggingFace ---
# For HuggingFace models
HUGGINGFACE_API_KEY=

# --- OpenRouter ---
# For routing to multiple providers
OPENROUTER_API_KEY=
QWEN_API_KEY=
MOONSHOT_API_KEY=
ZAI_API_KEY=

# Hugging Face token (for gated repos / model downloads)
HF_TOKEN=

# ================================================
# CUSTOM/LOCAL LLM API KEYS
# ================================================

# Custom OpenAI-compatible endpoint #1
CUSTOM_OPENAI_API_KEY=
CUSTOM_OPENAI_API_IP=

# Custom OpenAI-compatible endpoint #2
CUSTOM_OPENAI2_API_KEY=
CUSTOM_OPENAI2_API_IP=

# ================================================
# LOCAL MODEL API KEYS
# ================================================
# Note: Most local model APIs don't require API keys

# Kobold API
KOBOLD_API_KEY=
KOBOLD_API_IP=http://127.0.0.1:5001/api/v1/generate

# Llama.cpp API
LLAMA_API_KEY=
LLAMA_API_IP=http://127.0.0.1:8080/completion

# Oobabooga API
OOBA_API_KEY=
OOBA_API_IP=http://127.0.0.1:5000/v1/chat/completions

# TabbyAPI
TABBY_API_KEY=
TABBY_API_IP=http://127.0.0.1:5000/v1/chat/completions

# vLLM API
VLLM_API_KEY=
VLLM_API_IP=http://127.0.0.1:8000/v1/chat/completions

# Ollama API
OLLAMA_API_KEY=
OLLAMA_API_IP=http://127.0.0.1:11434/v1/chat/completions

# Aphrodite API
APHRODITE_API_KEY=
APHRODITE_API_IP=http://127.0.0.1:8080/completion

# Base URL overrides (useful for tests/mocks)
OPENAI_API_BASE_URL=
MOCK_OPENAI_BASE_URL=

# ================================================
# TEXT-TO-SPEECH API KEYS
# ================================================

# ElevenLabs TTS
ELEVENLABS_API_KEY=

# OpenAI TTS (uses OPENAI_API_KEY above)

# ================================================
# SEARCH ENGINE API KEYS
# ================================================

# Bing Search API
BING_SEARCH_API_KEY=

# Brave Search API
BRAVE_SEARCH_API_KEY=
BRAVE_AI_API_KEY=

# Google Custom Search
GOOGLE_SEARCH_API_KEY=
GOOGLE_SEARCH_ENGINE_ID=

# Kagi Search API
KAGI_API_KEY=

# Tavily Search API
TAVILY_API_KEY=

# Baidu Search API
BAIDU_API_KEY=

# Yandex Search API
YANDEX_API_KEY=
YANDEX_SEARCH_ID=

# ================================================
# WEB SCRAPING API KEYS
# ================================================
WEB_SCRAPER_API_KEY=

# ================================================
# EMBEDDING SERVICE API KEYS
# ================================================
# For remote embedding services (if not using OpenAI)
EMBEDDING_API_KEY=
EMBEDDING_API_URL=

# ================================================
# VECTOR DATABASE API KEYS
# ================================================
# For remote vector DB services
VECTOR_DB_API_KEY=

# ================================================
# LOCAL LLM SETTINGS (llama.cpp / llamafile / ollama)
# ================================================
# Ollama host binding (used internally by Ollama handler); format host:port
OLLAMA_HOST=127.0.0.1:11434

# Hardened defaults for local-LLM handlers; may be overridden via config.
# When false, secret-like CLI flags (e.g., hf_token) are rejected. Prefer env vars instead (HF_TOKEN).
LOCAL_LLM_ALLOW_CLI_SECRETS=false
# Auto-select next free port if requested port is busy
LOCAL_LLM_PORT_AUTOSELECT=true
# Number of ports to probe beyond the start port
LOCAL_LLM_PORT_PROBE_MAX=10
# Comma-separated list of additional allowed base directories for file flags (templates/grammars/caches)
# Example: LOCAL_LLM_ALLOWED_PATHS=/opt/local_llm/templates,/opt/local_llm/grammars
LOCAL_LLM_ALLOWED_PATHS=

# Optional llama.cpp environment parameters (advanced; not required). Prefer server_args/config.
# LLAMA_OFFLINE=true
# LLAMA_ARG_MODEL=
# LLAMA_ARG_CTX_SIZE=
# LLAMA_ARG_THREADS=
# LLAMA_ARG_N_PREDICT=
# LLAMA_ARG_N_GPU_LAYERS=

# ================================================
# MCP UNIFIED (optional)
# ================================================
MCP_JWT_SECRET=
MCP_API_KEY_SALT=
MCP_LOG_LEVEL=INFO
# WebSocket security (required in production)
# Require authentication for WebSocket connections
MCP_WS_AUTH_REQUIRED=true
# Comma-separated list of allowed WS origins (no wildcard in production)
# Example: MCP_WS_ALLOWED_ORIGINS=http://localhost:8000,http://localhost:3000
MCP_WS_ALLOWED_ORIGINS=

# Enable/disable global rate limiting (enabled by default in code)
# MCP_RATE_LIMIT_ENABLED=true

# Redis-backed rate limiting for multi-node deployments
# MCP_RATE_LIMIT_USE_REDIS=false
# MCP_REDIS_URL=redis://localhost:6379/0

# Global RPM/Burst (applies when category-specific not provided)
# MCP_RATE_LIMIT_RPM=60
# MCP_RATE_LIMIT_BURST=10

# Category-specific rates (optional)
# Ingestion (writes/expensive): lower RPM recommended
# MCP_RATE_LIMIT_RPM_INGESTION=30
# MCP_RATE_LIMIT_BURST_INGESTION=5
# Read (retrieval): higher RPM ok
# MCP_RATE_LIMIT_RPM_READ=120

# Tool â†’ category mapping (choose one)
# 1) JSON inline example:
# MCP_TOOL_CATEGORY_MAP='{"ingest_media":"ingestion","media.search":"read"}'
# 2) YAML file example:
# MCP_TOOL_CATEGORY_MAP_FILE=tldw_Server_API/Config_Files/mcp_tool_categories.yaml

# mTLS (client certificate) enforcement via reverse proxy headers
# When MCP_CLIENT_CERT_REQUIRED=true, you must also set MCP_CLIENT_CERT_HEADER_VALUE
# to the exact value your proxy sets on successful verification.
# Only trusted proxies may assert this header (see MCP_TRUSTED_PROXY_IPS).
MCP_CLIENT_CERT_REQUIRED=false
MCP_CLIENT_CERT_HEADER=x-ssl-client-verify
MCP_CLIENT_CERT_HEADER_VALUE=
# Network trust settings for header acceptance
# Comma-separated IP/CIDR list of proxies permitted to assert client-cert headers
MCP_TRUSTED_PROXY_IPS=127.0.0.1/32,::1/128
# Honor X-Forwarded-For only when peer is a trusted proxy
MCP_TRUST_X_FORWARDED=false
MCP_TRUSTED_PROXY_DEPTH=1

# ================================================
# JOBS BACKEND (optional)
# ================================================
JOBS_DB_URL=
JOBS_LEASE_SECONDS=60
JOBS_LEASE_RENEW_SECONDS=30
JOBS_LEASE_RENEW_JITTER_SECONDS=5
CHATBOOKS_CORE_WORKER_ENABLED=true

# ================================================
# TESTING / CI TOGGLES (optional)
# ================================================
TEST_MODE=false
DISABLE_HEAVY_STARTUP=false
RUN_MOCK_OPENAI=false
DISABLE_NLTK_DOWNLOADS=true
ALLOW_NLTK_DOWNLOADS=false

# ================================================
# QUICK START INSTRUCTIONS
# ================================================
# 1. Copy this template:
#    cp .env.template .env
#
# 2. Add your API keys to the .env file:
#    nano .env  # or use your preferred editor
#
# 3. For single-user mode, at minimum set:
#    - SINGLE_USER_API_KEY (or use default)
#    - At least one LLM provider API key
#
# 4. For multi-user mode, at minimum set:
#    - AUTH_MODE=multi_user
#    - JWT_SECRET_KEY (REQUIRED - must be secure!)
#    - DATABASE_URL (if using PostgreSQL)
#    - At least one LLM provider API key
#
# 5. Ensure .env is not tracked by git:
#    git status  # Should NOT show .env file
#
# 6. Start the application:
#    python -m uvicorn tldw_Server_API.app.main:app --reload
#
# ================================================
# SECURITY CHECKLIST
# ================================================
# Before deploying to production, ensure:
# [ ] All CHANGE_ME values have been replaced with secure values
# [ ] JWT_SECRET_KEY is at least 32 characters of random data (multi-user mode)
# [ ] SINGLE_USER_API_KEY is set to a secure value (single-user mode)
# [ ] DATABASE_URL points to production database
# [ ] This file is NOT committed to version control
# [ ] Backup strategy is in place for secrets
# [ ] Secret rotation schedule is established
#
# ================================================
# NOTES
# ================================================
# - Environment variables override values in this file
# - All settings in this file override config.txt
# - Keep this file secure and never share it
# - You only need to fill in keys for services you use
# - For local models, API keys are usually not required
# ================================================
