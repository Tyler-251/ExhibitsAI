# Requirements.txt for tldw Server API. Sorted into categories.
# Audio
av  # For audio encoding/streaming
faster_whisper
kokoro_onnx
nemo_toolkit[asr]
huggingface_hub
pyannote.audio
pyannote.core
pyannote.database
pyannote.metrics
pyannote.pipeline
PyAudio
sounddevice
soundfile
#
# API-Server
aiofiles
aioresponses
asyncpg
aiosqlite
apscheduler
bleach
cachetools
pgvector
defusedxml
email-validator
fastapi
hypothesis
loguru
lxml
numpy
pandas
passlib
psutil
pydantic
pydantic_core
pydantic[email]
pytest
python-dotenv
python-jose
python_magic
python-multipart
prometheus-client
pynvml
PyYAML
redis
scikit_learn
scipy
slowapi
starlette
toml
tomli
tqdm
# API-Server AuthN/AuthZ/Security
keyring
puremagic
pycryptodomex
PyJWT
yara_python
#
# Chunking/Languages
chardet
fugashi
jieba
langdetect
nltk
tiktoken
# Optional for proposition engine (spaCy-based):
# spacy
# en-core-web-sm (model; install via: python -m spacy download en_core_web_sm)
#
# ETL/Document Parsing
docling
docx2txt
EbookLib
lxml
mwparserfromhell
mwxml
pymupdf
pymupdf4llm
pypandoc
pypandoc_binary
yt_dlp
#
# LLM Inference
onnxruntime
openai
torch
transformers
#
# ONNX Conversion
# mlx  # Optional: for Apple Silicon MLX variant of Parakeet (uncomment if on macOS)
optimum
#
# Re-Ranking
FlashRank
#
# Research
arxiv
#
# VectorDB
chromadb
#
# PostgreSQL Support (Optional)
# Uncomment if you want to use PostgreSQL backend instead of SQLite
psycopg
#
#Web-Related
argon2-cffi
beautifulsoup4
html2text
httpx
urllib3
playwright
playwright_stealth
Requests
tenacity
trafilatura
argon2-cffi==25.1.0
curl_cffi
brotli
zstandard

# OCR (optional)
# To enable the dots.ocr backend, install per upstream instructions:
#   - git clone https://github.com/rednote-hilab/dots.ocr.git && cd dots.ocr
#   - Install compatible PyTorch (see their README for CUDA/CPU variants)
#   - pip install -e .
#   - Download model weights: python3 tools/download_model.py
#   - For best performance, deploy a vLLM server with the downloaded weights
# After installation, the backend can be selected via API using `ocr_backend=dots`.
# Optional: control prompt with env var DOTS_OCR_PROMPT (default: prompt_ocr).
# If you prefer dependency pinning, you may try (uncomment to use, but upstream recommends manual setup):
# dots-ocr @ git+https://github.com/rednote-hilab/dots.ocr.git

# To enable the POINTS-Reader backend, clone and install the repo and configure a CLI command:
#   - For local transformers: install WePOINTS toolkit and run via HF model `tencent/POINTS-Reader`
#       git clone https://github.com/WePOINTS/WePOINTS.git && cd WePOINTS && pip install -e .
#       (Recommended env: python==3.10.12, torch==2.5.1, transformers==4.55.2, cuda==12.1)
#   - For SGLang serving: `python -m sglang.launch_server --model-path tencent/POINTS-Reader --trust-remote-code --chat-template points-v15-chat --port 8081`
#   - Env selection:
#       export POINTS_MODE=sglang                # or transformers (default: auto)
#       export POINTS_SGLANG_URL=http://127.0.0.1:8081/v1/chat/completions
#       export POINTS_SGLANG_MODEL=WePoints
#       export POINTS_MODEL_PATH=tencent/POINTS-Reader
#       export POINTS_PROMPT='...'               # optional prompt override
# Select via API using `ocr_backend=points`.
